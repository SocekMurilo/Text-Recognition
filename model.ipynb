{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n",
    "pip install tensorflow\n",
    "\n",
    "pip install wrapt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.11 install opencv-python\n",
    "!pip3.11 install tensorflow\n",
    "!pip3.11 install wrapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "from tensorflow.keras import models, layers, activations, \\\n",
    "optimizers, utils, losses, initializers, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'testing'\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "patience = 5\n",
    "learning_rate = 0.001\n",
    "model_path = f'checkpoints/{folder_path}/test_model5.keras'\n",
    "exists = os.path.exists(model_path)\n",
    "\n",
    "# Carrega modelo se já existir um checkpoint, caso contrário, o cria.\n",
    "if exists:\n",
    "    model = models.load_model(model_path)\n",
    "else: \n",
    "    model = models.Sequential([\n",
    "        layers.Resizing(32, 32),\n",
    "        layers.Rescaling(1.0/255),\n",
    "        layers.BatchNormalization(axis=1),\n",
    "        layers.RandomRotation((-0.05, 0.05)),\n",
    "        layers.Conv2D(32, (3, 3),\n",
    "            activation = 'relu',\n",
    "            kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "        # layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(48, (3, 3),\n",
    "            activation = 'relu',\n",
    "            kernel_initializer = initializers.RandomNormal()\n",
    "        ),\n",
    "        # layers.MaxPooling2D((2, 2)), # tirar dps\n",
    "        layers.Conv2D(32, (3, 3),\n",
    "            activation = 'relu',\n",
    "            kernel_initializer = initializers.RandomNormal()\n",
    "        ),\n",
    "        # layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128,\n",
    "            activation = 'relu',\n",
    "            kernel_initializer = initializers.RandomNormal()\n",
    "        ),\n",
    "        layers.Dense(80,\n",
    "            activation = 'relu',\n",
    "            kernel_initializer = initializers.RandomNormal()\n",
    "        ),\n",
    "        layers.Dense(64,\n",
    "            activation = 'relu',\n",
    "            kernel_initializer = initializers.RandomNormal()\n",
    "        ),\n",
    "        layers.Dense(62,\n",
    "            activation = 'sigmoid',\n",
    "            kernel_initializer = initializers.RandomNormal()\n",
    "        )\n",
    "        ])\n",
    "\n",
    "if exists:\n",
    "    model.summary()\n",
    "else:\n",
    "    model.compile(\n",
    "    optimizer = optimizers.Adam(\n",
    "    learning_rate = learning_rate\n",
    "),\n",
    "    loss = losses.SparseCategoricalCrossentropy(), # trocar \n",
    "    metrics = [ 'accuracy' ]\n",
    ")\n",
    "    \n",
    "train = utils.image_dataset_from_directory(\n",
    "    \"organizedData\",\n",
    "    validation_split= 0.2,\n",
    "    subset= \"training\",\n",
    "    seed= 123,\n",
    "    shuffle= True,\n",
    "    image_size= (1200, 900),\n",
    "    batch_size= batch_size\n",
    "    )\n",
    "\n",
    "test = utils.image_dataset_from_directory(\n",
    "    \"organizedData\",\n",
    "    validation_split= 0.2,\n",
    "    subset= \"validation\",\n",
    "    seed= 123,\n",
    "    shuffle= True,\n",
    "    image_size= (1200, 900),\n",
    "    batch_size= batch_size\n",
    "    )\n",
    "\n",
    "model.fit(train,\n",
    "    epochs = epochs,\n",
    "    validation_data = test,\n",
    "    callbacks= [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience,\n",
    "            verbose = 1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath = model_path,\n",
    "            save_weights_only = False,\n",
    "            monitor = 'loss',\n",
    "            mode = 'min',\n",
    "            save_best_only = True\n",
    "        ),\n",
    "        # callbacks.LearningRateScheduler(\n",
    "        #     lambda epoch, lr : 1e-3 * 10 ** -(epoch / 20)\n",
    "        # )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
